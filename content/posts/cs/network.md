---
title: "Network"
date: 2023-07-29T11:04:35+08:00
lastmod: 2023-07-29T11:04:35+08:00
author: ["chx9"]
keywords: 
- 
categories: # 没有分类界面可以不填写
- 
tags: # 标签
- 
description: ""
weight:
slug: ""
draft: false # 是否为草稿
comments: true # 本页面是否显示评论
reward: false # 打赏
mermaid: true #是否开启mermaid
showToc: true # 显示目录
TocOpen: true # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示路径
cover:
    image: "" #图片路径例如：posts/tech/123/123.png
    zoom: # 图片大小，例如填写 50% 表示原图像的一半大小
    caption: "" #图片底部描述
    alt: ""
    relative: false
---



# 为什么TCP要三次握手？
- 最主要原因就是防止「历史连接」初始化了连接。
- 三次握手才可以同步双方的初始序列号
![image](/upload/2023/03/image.png)
![image-1679044159850](/upload/2023/03/image-1679044159850.png)
# 为什么TCP要四次挥手
- 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。

# TCP三次握手失败会发生什么
## 第一次握手失败
- 客户端重传SYN包，直到连接成功或者超时（每次等待两倍时间）
- 如果服务器无法响应，那么会发送RST包，表示拒绝连接

## 第二次握手失败
- 客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。
- 服务端这边会触发超时重传机制，重传 SYN-ACK 报文。

## 第三次握手失败
因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。
注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文

# 列举常用的HTTP状态码
HTTP状态码是指在HTTP协议中，服务器向客户端返回的响应状态码。HTTP状态码由三位数字组成，第一位数字表示响应类型，后两位数字没有具体分类作用。常见的HTTP状态码如下：

- 1xx：信息响应类，表示服务器已接收到客户端的请求，需要进一步处理。
- 2xx：成功响应类，表示服务器已成功地接收到客户端的请求并返回响应结果。
- 3xx：重定向响应类，表示客户端需要进一步操作才能完成请求，如重定向到其他URL。
- 4xx：客户端错误响应类，表示客户端请求存在错误或无法被服务器处理。
- 5xx：服务器错误响应类，表示服务器在处理请求时出现了错误或异常。

以下是常见的HTTP状态码及其含义：

- 200 OK：表示请求被成功处理，并返回响应结果。
- 301 Moved Permanently：表示请求的资源已经被永久移动到新的位置，客户端需要使用新的URL。
- 302 Found：表示请求的资源已经被暂时移动到新的位置，客户端需要使用新的URL，但是之后可能会恢复原来的位置。
- 304 Not Modified：表示客户端发送了一个条件请求，并且服务器认为客户端请求的资源没有被修改，因此不需要返回资源的实体内容，只需要返回响应头信息即可。
- 404 Not Found：表示请求的资源不存在或无法被找到。
- 500 Internal Server Error：表示服务器在处理请求时出现了未知的错误或异常。

除了上述常见的HTTP状态码，HTTP协议中还有很多其他状态码，每个状态码都有其特定的含义和用途。在编写Web应用程序时，了解HTTP状态码的含义和使用方法，可以帮助我们更好地处理HTTP请求，提高程序的可靠性和稳定性。

# GET和POST请求
GET和POST是HTTP协议中最常用的两种请求方法，它们有以下区别：

1. 参数传递方式：GET请求将参数以URL参数的形式传递，而POST请求将参数包含在请求体中传递。

2. 安全性：GET请求的参数会被包含在URL中，因此可能会被浏览器缓存、历史记录、代理服务器等记录下来，并且容易被攻击者截取、篡改或者伪造。POST请求的参数则不会被包含在URL中，相对来说更加安全。

3. 请求体大小限制：GET请求对请求体大小没有限制，但是浏览器对URL长度有限制；POST请求对请求体大小有限制，一般情况下不会超过2MB。

4. 应用场景：GET请求适合请求数据，如获取页面、搜索等操作；POST请求适合提交数据，如提交表单、上传文件等操作。

# HTTP和HTTPS

HTTP（Hypertext Transfer Protocol）和HTTPS（Hypertext Transfer Protocol Secure）都是用于在Web上进行数据传输的协议，它们的主要区别在于安全性：

1. 安全性：HTTP是明文传输协议，数据在传输过程中没有加密，容易被窃听和篡改；HTTPS利用SSL/TLS协议进行数据加密和身份认证，可以保证数据传输的安全性。

2. 端口号：HTTP使用的端口号为80，而HTTPS使用的端口号为443。

3. 证书：HTTPS需要使用数字证书对网站进行身份验证，证书由受信任的第三方机构颁发，可以保证网站的真实性和安全性；而HTTP没有身份验证机制，无法保证网站的真实性和安全性。

4. 性能：HTTPS比HTTP的性能要差一些，因为HTTPS需要进行加密和解密操作，会增加服务器和客户端的处理负担，导致响应速度变慢。


# http加密过程
HTTPS（Hypertext Transfer Protocol Secure）是一个用于安全传输数据的协议，它使用SSL（Secure Sockets Layer）或TLS（Transport Layer Security）协议来加密Web通信。以下是HTTPS的加密过程：

1. 客户端发起HTTPS请求，请求连接到服务器。

2. 服务器向客户端发送一个证书，证书中包含了服务器的公钥、证书的有效期、证书颁发机构等信息。

3. 客户端收到证书后，会验证证书的有效性，包括证书是否过期、证书颁发机构是否可信等。如果证书有效，客户端会生成一个随机数，用于后续的加密通信。

4. 客户端使用服务器的公钥加密随机数，并将加密后的随机数发送给服务器。

5. 服务器使用自己的私钥解密客户端发来的随机数，并使用该随机数作为对称加密算法的密钥，用于后续的数据加密。

6. 服务器使用对称加密算法对数据进行加密，并将加密后的数据发送给客户端。

7. 客户端使用之前生成的随机数作为对称加密算法的密钥，解密服务器发来的数据，从而得到原始数据。

以上就是HTTPS的加密过程，通过使用SSL或TLS协议，可以确保数据在传输过程中的机密性、完整性和真实性。

# 输入网址到出现网页的全过程
输入网址到浏览器中，到收到网页的整个过程大致可以分为以下步骤：

1. DNS解析：浏览器首先会解析输入的网址中的域名，将其转换为对应的IP地址。浏览器会先查找本地DNS缓存，如果没有找到匹配的IP地址，则会向DNS服务器发送请求，获取对应域名的IP地址。

2. 建立TCP连接：浏览器向服务器发送TCP连接请求，建立TCP连接。在这个过程中，浏览器和服务器会通过三次握手协议建立连接。

3. 发送HTTP请求：浏览器向服务器发送HTTP请求，请求获取特定资源，比如HTML、CSS、JavaScript、图片等。

4. 服务器响应：服务器接收到浏览器的HTTP请求后，会返回相应的资源内容以及HTTP状态码。

5. 浏览器渲染：当浏览器接收到服务器返回的资源内容后，会根据HTML、CSS和JavaScript等文件进行解析，生成DOM和CSSOM树，并将其合并成渲染树。然后浏览器会根据渲染树进行布局和绘制，最终将网页内容显示在用户界面上。

在这个过程中，涉及到的协议主要有：

1. DNS协议：用于域名解析，将域名转换为对应的IP地址。

2. TCP协议：用于在浏览器和服务器之间建立可靠的连接，确保数据的可靠传输。

3. HTTP协议：用于在浏览器和服务器之间传输资源内容，包括HTML、CSS、JavaScript、图片等。

4. HTTPS协议：用于在HTTP协议的基础上添加SSL/TLS协议进行加密通信，提高数据传输的安全性。

# TCP拥塞控制
https://www.bilibili.com/video/BV1L4411a7RN/?spm_id_from=333.337.search-card.all.click&vd_source=88a9ec90f0dcb5eb62f1a86d6d8d0ad4
https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6
拥塞控制是一种网络流量控制机制，它通过限制数据流的速度来防止网络拥塞和保持网络的稳定性。拥塞控制的几个常见机制包括：

1. 慢启动：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。相当于2的指数倍增长 。

2. 拥塞避免：每当收到一个 ACK 时，cwnd 增加 1/cwnd，变成了线性增长。

3. 快速重传：当发送方发现某个数据包没有收到确认时，它会重传该数据包。然而，如果发送方连续发送了多个数据包而没有收到确认，它会认为网络出现了拥塞，并立即减慢发送速率。幸运的是，由于TCP采用的是累计确认机制，即当接收端收到比期望序号大的报文段时，便会重复发送最近一次确认的报文段的确认信号，我们称之为冗余ACK（duplicate ACK）。
```
如图所示，报文段1成功接收并被确认ACK 2，接收端的期待序号为2，当报文段2丢失，报文段3失序到来，与接收端的期望不匹配，接收端重复发送冗余ACK 2。

这样，如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK（其实是收到4个同样的ACK，第一个是正常的，后三个才是冗余的），发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出，大大提高了效率。这便是快速重传机制。
```
![image-1679489336457](/upload/2023/03/image-1679489336457.png)
4. 快速恢复：当发送方减慢发送速率时，接收方会通知发送方可以增加发送速率。这种机制称为快速恢复，它可以帮助发送方更快地恢复正常的发送速率，而不是像慢启动一样重新开始。
```
正如前面所说，进入快速恢复之前，cwnd 和 ssthresh 已被更新了：

cwnd = cwnd/2 ，也就是设置为原来的一半;
ssthresh = cwnd;
然后，进入快速恢复算法如下：

拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；
重传丢失的数据包；
如果再收到重复的 ACK，那么 cwnd 增加 1；
如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；
```
![image-1679489653296](/upload/2023/03/image-1679489653296.png)
总之，拥塞控制的几个机制都是为了确保网络的稳定性和可靠性。通过限制数据流的速度，网络可以避免拥塞和数据包丢失，从而提高网络的性能和效率。。
TCP拥塞控制主要解决网络拥塞的问题。当网络中的数据流量超过网络的容量时，数据包就会被丢弃或延迟，从而导致网络性能下降。这种情况称为网络拥塞。

TCP拥塞控制通过限制数据流的速度来避免网络拥塞的发生，并保持网络的稳定性。具体来说，TCP拥塞控制通过动态调整数据发送速率来控制网络的拥塞程度。当网络容量达到极限时，TCP会减慢数据发送速率来避免数据包的丢失和拥塞。当网络空闲时，TCP会逐渐增加数据发送速率，以充分利用网络带宽。

TCP拥塞控制的另一个重要作用是避免网络拥塞引起的全局性故障。如果一个节点开始发送大量的数据而不进行拥塞控制，它会导致网络拥塞并影响到其他节点的通信。这种情况称为全局性故障。TCP拥塞控制可以帮助避免这种情况发生，从而保持整个网络的稳定性和可靠性。

总之，TCP拥塞控制的主要目的是避免网络拥塞和保持网络的稳定性。通过限制数据流的速度来控制网络的拥塞程度，TCP可以确保数据包的传输和网络的性能，从而提高网络的效率和可靠性。
# 流量控制和拥塞控制分别解决了什么问题
流量控制是指在数据发送方和接收方之间控制数据流的速度，以避免接收方缓存区被溢出。TCP的窗口机制通过动态调整发送方的窗口大小来实现流量控制。发送方会根据接收方的窗口大小来控制发送数据的速度，以确保接收方能够及时处理接收到的数据。如果接收方的缓存区已满，则发送方会停止发送数据，直到接收方处理完已接收的数据并释放出足够的缓存区空间。

拥塞控制是指在网络拥塞时避免过多的数据流入网络，从而导致数据包的丢失和延迟。TCP的窗口机制通过动态调整发送方的窗口大小来实现拥塞控制。当网络拥塞时，接收方会发送一个拥塞通知给发送方，告知发送方减小发送数据的速度。发送方会根据接收到的拥塞通知来调整窗口大小，以降低发送数据的速度。
# http长连接和短链接区别
HTTP的长连接和短连接是指在HTTP协议下，客户端与服务器之间的TCP连接是否保持长时间开启的不同方式。

短连接：客户端向服务器发送HTTP请求，服务器响应后立即关闭TCP连接。下次请求时需要重新建立TCP连接。在HTTP/1.0中，默认采用短连接。

长连接：客户端向服务器发送HTTP请求，服务器响应后保持TCP连接不关闭，继续等待下一次请求。下次请求时，可以复用已经建立的TCP连接。在HTTP/1.1中，默认采用长连接。

长连接的优点是减少了TCP连接建立和关闭的开销，提高了性能。同时，长连接使得浏览器可以同时发起多个请求，而不需要等待上一个请求的响应。这样可以减少客户端请求的延迟，提高了用户体验。

短连接的优点是在请求结束后立即关闭TCP连接，释放资源，避免了因为长连接占用资源过多而导致的系统崩溃。同时，短连接适用于一次请求就能完整响应的场景，如HTTP/1.0中的大部分请求。

总之，长连接和短连接各有优缺点，具体使用哪种连接方式应根据场景和需求来确定。
长连接适用于以下场景：

1. 频繁通信的场景，如聊天、在线游戏等。

2. 需要多次请求的场景，如浏览器渲染网页时需要请求多个资源，使用长连接可以减少TCP连接建立和关闭的开销。

3. 需要实时推送数据的场景，如股票行情、天气预报等。

短连接适用于以下场景：

1. 请求结束后立即释放连接的场景，如HTTP/1.0中的大部分请求。

2. 非频繁通信的场景，如客户端向服务器请求静态资源。

总之，长连接适用于需要频繁通信、多次请求或需要实时推送数据的场景，而短连接适用于请求结束后立即释放连接的场景和非频繁通信的场景。但是，具体使用哪种连接方式还应根据实际情况和需求来确定。
# 哪些用UDP哪些用TCP
应用层协议可以使用TCP或UDP进行数据传输，具体使用哪种传输协议，需要根据协议的特性和应用场景进行选择。下面是一些常见的应用层协议及其使用的传输协议：

使用TCP传输的应用层协议：

1. HTTP协议：用于Web应用程序的数据传输。

2. FTP协议：用于文件传输，支持文件上传和下载等操作。

3. SMTP协议：用于电子邮件的传输。

4. SSH协议：用于安全远程登录和文件传输。

5. Telnet协议：用于远程登录主机进行命令行操作。

使用UDP传输的应用层协议：

1. DNS协议：用于域名解析，将域名转换为IP地址。

2. DHCP协议：用于动态IP地址分配，自动分配和管理IP地址。

3. TFTP协议：用于简单文件传输，支持无连接传输方式。

4. SNMP协议：用于网络管理和监控，实现对网络设备的远程管理。

5. RTP协议：用于音视频数据的传输，支持实时传输和流媒体播放。

需要注意的是，有些应用层协议同时支持TCP和UDP传输，如DNS协议和FTP协议等，可以根据实际情况进行选择。
# https ssl连接的过程
HTTPS加密过程简略如下：

1. 客户端发送HTTPS请求，请求头中的`https`字段设置为`on`。

2. 服务器返回数字证书，包含服务器的公钥、证书颁发机构的信息、证书有效期等。

3. 客户端验证证书合法性，确认无误后生成随机的会话密钥，并使用服务器的公钥将其加密后发送给服务器。

4. 服务器使用自己的私钥解密会话密钥，得到原始的会话密钥。

5. 双方使用会话密钥进行对称加密，保证通信过程中的数据安全性，并进行数字签名和身份认证，确保通信的可信性和完整性。
# http1.0和http1.1和http2.0的差别，分别做了哪几点优化
HTTP是一种应用层协议，常用于Web应用中，目前主要有HTTP/1.0、HTTP/1.1和HTTP/2.0三个版本。它们之间的主要差别及优化如下：

1. HTTP/1.0和HTTP/1.1的主要差别

- 缓存处理：HTTP/1.0中缓存处理能力较弱，只能使用header中的`Expires`字段和`Last-Modified`字段判断缓存是否过期，而HTTP/1.1引入了更多的缓存控制字段，如`Cache-Control`、`ETag`和`If-None-Match`、`last-modified-since`等。
```
Cache-Control：用于控制缓存的行为，例如最大缓存时间、缓存是否需要重新验证等。常见的取值包括max-age（缓存最大时间）、no-cache（需要重新验证缓存）等。

ETag（Entity Tag）：用于标识资源的唯一标识符，通常是一个字符串。当资源发生变化时，ETag的值也会发生变化。客户端可以通过If-None-Match请求头将上次请求的ETag值发送给服务器，服务器检查该值是否与当前资源的ETag值相同，如果相同，则返回304 Not Modified，表示资源未被修改。

If-None-Match：客户端发送的请求头，用于告诉服务器上次请求资源时的ETag值。服务器可以通过比较该值和当前资源的ETag值来判断资源是否被修改。

Last-Modified-Since：服务器返回的响应头，用于表示资源最后一次被修改的时间。客户端可以通过If-Modified-Since请求头将上次请求资源时的最后修改时间发送给服务器，服务器检查该值是否与当前资源的最后修改时间相同，如果相同，则返回304 Not Modified，表示资源未被修改。
```
- 持久连接：HTTP/1.0每次请求都需要建立和断开连接，效率较低，而HTTP/1.1引入了持久连接，即同一个TCP连接可以传输多个HTTP请求和响应，减少了连接建立和断开的开销。
- Host头处理：HTTP/1.0中没有Host头，因此无法处理多个域名的请求，而HTTP/1.1中通过Host头实现了虚拟主机的处理。
- 管道机制：HTTP/1.1支持管道机制，即在一个TCP连接中同时发送多个请求，减少了响应时间和网络带宽的开销。

2. HTTP/1.1和HTTP/2.0的主要差别

- 多路复用：HTTP/2.0中支持多路复用，即一个TCP连接可以同时传输多个HTTP请求和响应，避免了HTTP/1.1中的队头阻塞问题，提高了网站的性能和速度。
- 二进制分帧：HTTP/2.0中将HTTP报文分解为二进制帧，每个帧都有自己的帧头和帧尾，便于传输和处理，提高了传输效率。
- 头部压缩：HTTP/2.0中引入了HPACK算法进行头部压缩，减少了头部信息的传输量，提高了传输效率。
- 服务器推送：HTTP/2.0中支持服务器推送，即在客户端发送请求前，服务器可以主动推送相关的资源，避免了客户端重复请求的问题，提高了网站的性能和速度。

总之，HTTP/1.1和HTTP/2.0相比较而言，HTTP/2.0在性能和速度方面有很大的提升，更加适合现代Web应用。
HTTP/1.0和HTTP/1.1的缓存处理机制有以下几点差别：


# tcp粘包现象
TCP粘包现象指的是发送方将多个独立的数据包一起发送，接收方在接收数据时却可能会将多个数据包合并成一个数据包，从而导致数据包粘连在一起的现象。这种现象主要是由于TCP协议的流模式特性引起的。

TCP协议是基于字节流的传输协议，发送端将数据按照字节流发送，而接收端则根据数据大小进行接收，这就可能导致多个数据包合并在一起接收，从而产生粘包现象。

TCP粘包现象的原因主要有以下几个方面：

1. 发送方发送速度过快：发送方发送数据的速度过快，接收方来不及处理每个数据包，从而导致多个数据包合并在一起接收。

2. 数据包大小不固定：发送方发送的数据包大小不固定，接收方在接收时难以确定每个数据包的边界，从而导致多个数据包合并在一起接收。

3. 网络拥堵：网络拥堵会导致数据包的延迟和丢失，从而导致多个数据包合并在一起接收。

解决TCP粘包现象的方法主要有以下几种：

1. 增加消息边界：在消息头部添加消息长度字段，接收方根据消息长度进行数据的切割。

2. 使用固定长度的消息：发送方将消息按照固定长度进行分割，接收方根据固定长度进行数据的切割。

3. 使用特殊字符作为消息分隔符：发送方在消息尾部添加特殊字符作为消息分隔符，接收方根据特殊字符进行数据的切割。

4. 使用应用层协议：在应用层协议中规定消息的格式和边界，从而避免粘包现象的发生。

总之，解决TCP粘包现象的方法需要根据具体应用场景进行选择，需要考虑消息大小、消息格式、传输效率、可靠性等因素。
# POST和GET请求
GET和POST是HTTP协议中常用的两种请求方法，它们在数据传输、安全性、请求体大小等方面有所不同。

GET请求方法是用于从服务器获取数据的方法，该方法将请求参数附加在URL的末尾，以问号(?)的形式分隔URL和请求参数，多个请求参数之间以&符号分隔。因此，GET请求方法的请求体大小有限制，通常不超过2KB。

POST请求方法是用于向服务器提交数据的方法，该方法将请求参数放在请求体中，请求体的格式由Content-Type头部指定。因为POST请求方法将请求参数放在请求体中，所以请求体的大小没有限制，可以传输较大的数据。

GET和POST请求方法在安全性方面也有所不同。由于GET请求方法将请求参数附加在URL的末尾，所以请求参数会暴露在URL中，容易被中间人攻击截获和篡改。而POST请求方法将请求参数放在请求体中，相对安全一些。

幂等性：GET请求方法具有幂等性，即多次请求返回的结果相同，不会对服务器产生影响。而POST请求方法不具有幂等性，多次请求可能会产生不同的结果，对服务器产生影响。

总之，GET和POST请求方法在数据传输、安全性、请求体大小等方面有所不同。一般来说，GET请求方法用于从服务器获取数据，POST请求方法用于向服务器提交数据。当需要传输大量数据或者涉及到敏感数据时，建议使用POST请求方法。

# tcp如何保证可靠
TCP（Transmission Control Protocol）是一种面向连接的、可靠的传输协议，它通过以下机制来保证数据传输的可靠性：

1. 序列号与确认应答机制：每个TCP报文段都有一个唯一的序列号和确认应答号，用于保证数据的顺序性和完整性。发送端将数据分成若干个报文段发送，每个报文段都有一个序列号，接收端收到报文段后需向发送端发送确认应答，确认应答号为接收到的数据的下一个期望的序列号。如果发送端接收到确认应答，就认为该报文段已经成功传输，可以将该报文段从发送缓冲区中删除。

2. 超时重传机制：发送端在发送数据时会启动一个定时器，如果在指定时间内没有收到接收端的确认应答，发送端会判断该报文段丢失了，需要重新发送。接收端收到重复的报文段时，会丢弃该报文段，同时向发送端发送确认应答。

3. 滑动窗口机制：TCP使用滑动窗口机制来实现流量控制和拥塞控制。发送端和接收端都有一个窗口大小，用于限制发送和接收数据的速率。发送端发送数据时，需要等待接收端发送的确认应答，确认应答中包含接收端当前窗口的大小，发送端根据窗口大小来调整发送数据的速率。

4. 拥塞控制

5. 校验和：校验和（checksum）是一种用于检测数据传输过程中是否发生错误的技术。在数据传输过程中，可能会出现各种各样的错误，比如说数据损坏、数据重复、数据丢失等，这些错误都可能导致数据传输失败或者数据被篡改。校验和技术可以通过计算数据的校验和值来检测这些错误，从而保证数据传输的可靠性。

通过以上机制，TCP可以保证数据传输的可靠性，并且在网络出现拥塞时可以进行拥塞控制，避免网络拥塞导致数据丢失或传输延迟增加。
# 滑动窗口
https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3
# ping的过程
主要是icmp
Ping是一种常用的网络诊断工具，用于测试主机之间的连通性。当我们使用Ping命令时，Ping程序会执行以下步骤：

1. 发送ICMP Echo Request消息：Ping程序向目标主机发送一个ICMP Echo Request消息，该消息包含一个随机的标识符和序列号。

2. 接收ICMP Echo Reply消息：目标主机收到ICMP Echo Request消息后，会向发送方返回一个ICMP Echo Reply消息，该消息包含与Echo Request消息相同的标识符和序列号。

3. 计算往返时间（RTT）：Ping程序在接收到Echo Reply消息后，会计算从发送Echo Request消息到接收Echo Reply消息所需的时间，即往返时间（RTT）。

4. 显示结果：Ping程序将计算得到的RTT值和其他一些统计信息显示在屏幕上。如果目标主机无法到达，Ping程序会返回一个错误消息。

需要注意的是，Ping命令使用的是ICMP协议，而不是TCP或UDP协议。因此，Ping命令可以用于测试主机之间的连通性，但不能用于测试TCP或UDP服务的可用性。此外，由于ICMP消息可以被防火墙和路由器过滤，因此在某些情况下，Ping命令可能无法正常工作。
# mac寻址和ip寻址的差异
mac寻址在数据链路层，ip寻址在网络层

# 数据链路层的作用
1、封装成帧
2、流量控制
3、差错控制
4、mac寻址
5、透明传输
# 网络层的作用

**管理数据包的传输和路由选择**，将数据包从源节点传输到目的节点。
实现**IP（Internet Protocol）协议，负责数据包的分组、传输和路由选择**。

提供差错控制和流量控制功能，确保数据包传输的可靠性和效率。

实现路由选择算法，根据网络拓扑结构和路由策略选择最佳的路径将数据包传输到目的节点。

实现地址转换（NAT，Network Address Translation）等功能，将内部私有地址转换为公网可用的地址，以实现网络连接与安全性的需求。
  # 子网掩码
  子网掩码（subnet mask）是用于划分**网络地址和主机地址**的一个32位数值，用于告诉网络设备哪些位是网络地址，哪些位是主机地址。子网掩码通常与IP地址配合使用，用于指示网络中哪些位是网络地址，哪些位是主机地址。

子网掩码的作用是将一个IP地址分成两部分：网络地址和主机地址。网络地址用于标识网络，而主机地址用于标识特定的主机。

子网掩码的格式通常是四个8位二进制数，例如255.255.255.0。这个子网掩码表示前24位是网络地址，后8位是主机地址。这意味着，对于该子网掩码的网络，可以有256个主机地址（2的8次方），因为最后8位可以有256种不同的组合。

在计算机网络中，子网掩码有助于划分网络和管理IP地址。通过使用子网掩码，网络管理员可以将一个大的IP地址空间分成多个子网，以便更有效地管理网络。例如，一个大的IP地址空间可以划分为多个小的子网，每个子网可以被分配给不同的部门或办公室，以便更好地管理网络流量和安全。
# UDP和TCP的区别，适用场景
TCP 适用于对数据传输的可靠性要求较高的场景，如文件传输（ftp）、电子邮件（stmp）、网页浏览（http）等；UDP 适用于对数据传输的可靠性要求较低、数据传输速度要求较高的场景，如在线游戏、实时音视频、DNS 等。

# 为什么会出现大量的close_wait状态，如何解决
time_wait 是指一个网络连接在关闭之后，等待一段时间才能被操作系统关闭的状态。在这个状态下，连接的双方不能再进行数据传输，但是连接所占用的资源仍然未被释放。

大量出现 time_wait 状态的原因可能包括以下几个方面：

- 短时间内建立和关闭大量的连接。如果一个程序在短时间内频繁地建立和关闭连接，可能会导致大量的连接处于 time_wait 状态。

- 连接的关闭过程不规范。如果连接的关闭过程不规范，例如未及时调用 close 函数，可能会导致连接一直处于 time_wait 状态。

- 连接的双方协议不兼容。如果连接的双方使用的协议不兼容，可能会导致连接在关闭时出现异常，从而产生大量的 time_wait 状态。

对于大量出现 time_wait 状态的情况，可以采取以下几种处理方法：

- 调整 TCP 参数。可以通过修改操作系统的 TCP 参数，例如修改 TIME_WAIT 的时间等，来减少 time_wait 状态的数量。

- 优化程序设计。可以通过优化程序的设计，例如使用连接池等技术，来减少连接的建立和关闭次数，从而减少 time_wait 状态的出现。

- 使用 SO_REUSEADDR 选项。可以在程序中使用 SO_REUSEADDR 选项，来允许多个连接共用同一个端口，从而减少 time_wait 状态的数量。

- 使用负载均衡器。可以使用负载均衡器来分摊连接的负载，从而减少单个程序的连接数量，从而减少 time_wait 状态的出现。

总之，对于大量出现 time_wait 状态的情况，需要根据具体的情况采取不同的处理方法。
# 交换机位于哪一层
交换机位于数据链层，负责在同一网络下中转发数据帧。它能够根据目标 MAC 地址来决定数据帧的转发路径，以实现同一网络内的通信。
路由器是一种网络设备，主要用于在不同的网络之间转发数据包。
# 五层网络中的各层协议有啥
![image-1681115400639](/upload/2023/04/image-1681115400639.png)

# DNS过程
以下是DNS解析www.example的过程：

1. 当用户在浏览器中输入www.example时，浏览器会向本地DNS服务器发送DNS解析请求。

2. 如果本地DNS服务器缓存了该域名的解析信息，它将直接返回该域名的IP地址。否则，它将向根域名服务器发送请求。

3. 根域名服务器将返回.com顶级域名服务器的地址。

4. 本地DNS服务器随后向.com顶级域名服务器发送请求，并返回该域名的权威域名服务器地址。

5. 本地DNS服务器向该权威域名服务器发送请求，并返回该域名的IP地址。

6. 本地DNS服务器将该IP地址缓存起来，并将其返回给用户的计算机或设备。

7. 用户的计算机或设备使用该IP地址与该域名的服务器进行通信，以获取网站的内容。

